{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "paddyproject.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1a8Uyma3JjG3qWpQWrN8g6H_kMjBDvPXL",
      "authorship_tag": "ABX9TyO7U34/K4Dt/m6ZoPrVZ+4R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nishant2k/bird_classification/blob/master/paddyproject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8hgHkbDeToi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip \"/content/drive/My Drive/birds_data.zip\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4qRGz5O39Ch",
        "colab_type": "code",
        "outputId": "01370fbb-53c9-4b97-c771-4ca824b22856",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(os.listdir(\"/content/bird_f/train\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6009"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfGMvIFx43cv",
        "colab_type": "code",
        "outputId": "54e0f764-97aa-4725-8086-380de9a5a1a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "len(os.listdir(\"/content/bird_f/test\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1480"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stDORZidTiWc",
        "colab_type": "code",
        "outputId": "5777dc04-0424-4d5d-e3a9-b3e4b2975499",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\"\"\"Importing nc=ecessery libraries\"\"\"\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from glob import glob\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\"\"\"Function for building th model\"\"\"\n",
        "def build_model(size, num_classes):\n",
        "    inputs = Input((size, size, 3))\n",
        "    backbone = MobileNetV2(input_tensor=inputs, include_top=False, weights=\"imagenet\") #Used mobilenetV2 for better performance of our model.\n",
        "    backbone.trainable = True\n",
        "    x = backbone.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dropout(0.2)(x)\n",
        "    x = Dense(1024, activation=\"relu\")(x)\n",
        "    \n",
        "    #x = Dense(1024, activation=\"relu\")(x)\n",
        "    #x = Dense(1024, activation=\"relu\")(x) # No need to dence the layers because we are using MobileNetV2\n",
        "    x = Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "\n",
        "    model = tf.keras.Model(inputs, x)\n",
        "    return model\n",
        "\"\"\"Function for reading images\"\"\"\n",
        "def read_image(path, size):\n",
        "    image = cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "    image = cv2.resize(image, (size, size))\n",
        "    image = image / 255.0\n",
        "    image = image.astype(np.float32)\n",
        "    return image\n",
        "\n",
        "def parse_data(x, y):\n",
        "    x = x.decode()\n",
        "\n",
        "    num_class = 211\n",
        "    size = 224\n",
        "\n",
        "    image = read_image(x, size)\n",
        "    label = [0] * num_class\n",
        "    label[y] = 1\n",
        "    label = np.array(label)\n",
        "    label = label.astype(np.int32)\n",
        "\n",
        "    return image, label\n",
        "\n",
        "def tf_parse(x, y):\n",
        "    x, y = tf.numpy_function(parse_data, [x, y], [tf.float32, tf.int32])\n",
        "    x.set_shape((224, 224, 3))\n",
        "    y.set_shape((211))\n",
        "    return x, y\n",
        "\n",
        "\"\"\"Function for taking the image locations and taking out informations and storing them\"\"\"\n",
        "def tf_dataset(x, y, batch=8):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
        "    dataset = dataset.map(tf_parse)\n",
        "    dataset = dataset.batch(batch)\n",
        "    dataset = dataset.repeat()\n",
        "    return dataset\n",
        "\n",
        "\n",
        "path = \"/content/bird_f\" # Path of directory containing train,test and labels\n",
        "train_path = os.path.join(path, \"train/*\") #path of train dataset\n",
        "#test_path = os.path.join(path, \"test/*\")\n",
        "labels_path = os.path.join(path, \"train_labels.csv\") #labels of train datasets\n",
        "\n",
        "\n",
        "labels_df = pd.read_csv(labels_path) #Reading the train label\n",
        "breed = labels_df[\"breed\"].unique() # Making list of unique elements of breed of birds\n",
        "print(\"Number of Breed: \", len(breed))\n",
        "\n",
        "breed2id = {name: i for i, name in enumerate(breed)} #making dictionary for birds name with index\n",
        "id2breed = {i: name for i, name in enumerate(breed)} # vice-versa of breed2id\n",
        " \n",
        "\n",
        "ids = glob(train_path) # randomly shuffling and giving the path of train_path\n",
        "labels = []\n",
        "\n",
        "#Reading every image and taking their breed\n",
        "for image_id in ids: \n",
        "    image_id = image_id.split(\"/\")[-1].split(\".\")[0]\n",
        "    breed_name = list(labels_df[labels_df.id == image_id][\"breed\"])[0]\n",
        "    breed_idx = breed2id[breed_name]\n",
        "    labels.append(breed_idx)\n",
        "\n",
        "\n",
        "\"\"\"Splitting the data for training and validation\"\"\"\n",
        "train_x, valid_x = train_test_split(ids, test_size=0.2, random_state=42)\n",
        "train_y, valid_y = train_test_split(labels, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "size = 224\n",
        "num_classes = 211 # no. of breeds of birds\n",
        "lr = 1e-5 # learning rate of our model\n",
        "batch = 16\n",
        "epochs = 20\n",
        "\n",
        "    ## Building the DL model from the function created\n",
        "model = build_model(size, num_classes)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(lr), metrics=[\"acc\"])\n",
        "    \n",
        "\n",
        "    ## Taking the useful data from images\n",
        "train_dataset = tf_dataset(train_x, train_y, batch=batch)\n",
        "valid_dataset = tf_dataset(valid_x, valid_y, batch=batch)\n",
        "\n",
        "    ## Training\n",
        "callbacks = [\n",
        "        ModelCheckpoint(\"model3.h5\", verbose=1, save_best_only=True), #saving the model for further use \n",
        "        ReduceLROnPlateau(factor=0.1, patience=5, min_lr=1e-6)\n",
        "        ]\n",
        "train_steps = (len(train_x)//batch) + 1\n",
        "valid_steps = (len(valid_x)//batch) + 1\n",
        "#Final training the model\n",
        "model.fit(train_dataset,\n",
        "        steps_per_epoch=train_steps,\n",
        "        validation_steps=valid_steps,\n",
        "        validation_data=valid_dataset,\n",
        "        epochs=epochs,\n",
        "        callbacks=callbacks)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Breed:  211\n",
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "Epoch 1/20\n",
            "301/301 [==============================] - ETA: 0s - loss: 3.9049 - acc: 0.2361\n",
            "Epoch 00001: val_loss improved from inf to 3.87824, saving model to model3.h5\n",
            "301/301 [==============================] - 72s 238ms/step - loss: 3.9049 - acc: 0.2361 - val_loss: 3.8782 - val_acc: 0.1473 - lr: 1.0000e-05\n",
            "Epoch 2/20\n",
            "301/301 [==============================] - ETA: 0s - loss: 2.6612 - acc: 0.3747\n",
            "Epoch 00002: val_loss improved from 3.87824 to 3.47205, saving model to model3.h5\n",
            "301/301 [==============================] - 72s 239ms/step - loss: 2.6612 - acc: 0.3747 - val_loss: 3.4720 - val_acc: 0.2271 - lr: 1.0000e-05\n",
            "Epoch 3/20\n",
            "301/301 [==============================] - ETA: 0s - loss: 2.2463 - acc: 0.4606\n",
            "Epoch 00003: val_loss improved from 3.47205 to 3.16602, saving model to model3.h5\n",
            "301/301 [==============================] - 72s 238ms/step - loss: 2.2463 - acc: 0.4606 - val_loss: 3.1660 - val_acc: 0.2804 - lr: 1.0000e-05\n",
            "Epoch 4/20\n",
            "301/301 [==============================] - ETA: 0s - loss: 1.9575 - acc: 0.5382\n",
            "Epoch 00004: val_loss improved from 3.16602 to 2.87830, saving model to model3.h5\n",
            "301/301 [==============================] - 72s 239ms/step - loss: 1.9575 - acc: 0.5382 - val_loss: 2.8783 - val_acc: 0.3403 - lr: 1.0000e-05\n",
            "Epoch 5/20\n",
            "301/301 [==============================] - ETA: 0s - loss: 1.7165 - acc: 0.6110\n",
            "Epoch 00005: val_loss improved from 2.87830 to 2.59066, saving model to model3.h5\n",
            "301/301 [==============================] - 73s 243ms/step - loss: 1.7165 - acc: 0.6110 - val_loss: 2.5907 - val_acc: 0.3885 - lr: 1.0000e-05\n",
            "Epoch 6/20\n",
            "301/301 [==============================] - ETA: 0s - loss: 1.4847 - acc: 0.6882\n",
            "Epoch 00006: val_loss improved from 2.59066 to 2.31928, saving model to model3.h5\n",
            "301/301 [==============================] - 74s 244ms/step - loss: 1.4847 - acc: 0.6882 - val_loss: 2.3193 - val_acc: 0.4468 - lr: 1.0000e-05\n",
            "Epoch 7/20\n",
            "301/301 [==============================] - ETA: 0s - loss: 1.2867 - acc: 0.7398\n",
            "Epoch 00007: val_loss improved from 2.31928 to 2.08294, saving model to model3.h5\n",
            "301/301 [==============================] - 73s 241ms/step - loss: 1.2867 - acc: 0.7398 - val_loss: 2.0829 - val_acc: 0.5100 - lr: 1.0000e-05\n",
            "Epoch 8/20\n",
            "301/301 [==============================] - ETA: 0s - loss: 1.0963 - acc: 0.7916\n",
            "Epoch 00008: val_loss improved from 2.08294 to 1.86933, saving model to model3.h5\n",
            "301/301 [==============================] - 71s 236ms/step - loss: 1.0963 - acc: 0.7916 - val_loss: 1.8693 - val_acc: 0.5699 - lr: 1.0000e-05\n",
            "Epoch 9/20\n",
            "301/301 [==============================] - ETA: 0s - loss: 0.9334 - acc: 0.8288\n",
            "Epoch 00009: val_loss improved from 1.86933 to 1.66473, saving model to model3.h5\n",
            "301/301 [==============================] - 71s 236ms/step - loss: 0.9334 - acc: 0.8288 - val_loss: 1.6647 - val_acc: 0.6265 - lr: 1.0000e-05\n",
            "Epoch 10/20\n",
            "301/301 [==============================] - ETA: 0s - loss: 0.7901 - acc: 0.8646\n",
            "Epoch 00010: val_loss improved from 1.66473 to 1.49271, saving model to model3.h5\n",
            "301/301 [==============================] - 71s 237ms/step - loss: 0.7901 - acc: 0.8646 - val_loss: 1.4927 - val_acc: 0.6747 - lr: 1.0000e-05\n",
            "Epoch 11/20\n",
            "301/301 [==============================] - ETA: 0s - loss: 0.6633 - acc: 0.8904\n",
            "Epoch 00011: val_loss improved from 1.49271 to 1.33799, saving model to model3.h5\n",
            "301/301 [==============================] - 71s 236ms/step - loss: 0.6633 - acc: 0.8904 - val_loss: 1.3380 - val_acc: 0.7263 - lr: 1.0000e-05\n",
            "Epoch 12/20\n",
            "301/301 [==============================] - ETA: 0s - loss: 0.5593 - acc: 0.9103\n",
            "Epoch 00012: val_loss improved from 1.33799 to 1.19503, saving model to model3.h5\n",
            "301/301 [==============================] - 71s 235ms/step - loss: 0.5593 - acc: 0.9103 - val_loss: 1.1950 - val_acc: 0.7754 - lr: 1.0000e-05\n",
            "Epoch 13/20\n",
            "301/301 [==============================] - ETA: 0s - loss: 0.4702 - acc: 0.9245\n",
            "Epoch 00013: val_loss improved from 1.19503 to 1.09528, saving model to model3.h5\n",
            "301/301 [==============================] - 71s 236ms/step - loss: 0.4702 - acc: 0.9245 - val_loss: 1.0953 - val_acc: 0.8020 - lr: 1.0000e-05\n",
            "Epoch 14/20\n",
            "301/301 [==============================] - ETA: 0s - loss: 0.3927 - acc: 0.9393\n",
            "Epoch 00014: val_loss improved from 1.09528 to 1.02195, saving model to model3.h5\n",
            "301/301 [==============================] - 71s 235ms/step - loss: 0.3927 - acc: 0.9393 - val_loss: 1.0220 - val_acc: 0.8186 - lr: 1.0000e-05\n",
            "Epoch 15/20\n",
            "301/301 [==============================] - ETA: 0s - loss: 0.3297 - acc: 0.9494\n",
            "Epoch 00015: val_loss improved from 1.02195 to 0.96123, saving model to model3.h5\n",
            "301/301 [==============================] - 72s 238ms/step - loss: 0.3297 - acc: 0.9494 - val_loss: 0.9612 - val_acc: 0.8336 - lr: 1.0000e-05\n",
            "Epoch 16/20\n",
            "301/301 [==============================] - ETA: 0s - loss: 0.2740 - acc: 0.9590\n",
            "Epoch 00016: val_loss improved from 0.96123 to 0.93235, saving model to model3.h5\n",
            "301/301 [==============================] - 71s 235ms/step - loss: 0.2740 - acc: 0.9590 - val_loss: 0.9323 - val_acc: 0.8411 - lr: 1.0000e-05\n",
            "Epoch 17/20\n",
            "301/301 [==============================] - ETA: 0s - loss: 0.2283 - acc: 0.9682\n",
            "Epoch 00017: val_loss improved from 0.93235 to 0.90506, saving model to model3.h5\n",
            "301/301 [==============================] - 70s 232ms/step - loss: 0.2283 - acc: 0.9682 - val_loss: 0.9051 - val_acc: 0.8419 - lr: 1.0000e-05\n",
            "Epoch 18/20\n",
            "301/301 [==============================] - ETA: 0s - loss: 0.1852 - acc: 0.9771\n",
            "Epoch 00018: val_loss improved from 0.90506 to 0.88231, saving model to model3.h5\n",
            "301/301 [==============================] - 70s 233ms/step - loss: 0.1852 - acc: 0.9771 - val_loss: 0.8823 - val_acc: 0.8478 - lr: 1.0000e-05\n",
            "Epoch 19/20\n",
            "301/301 [==============================] - ETA: 0s - loss: 0.1489 - acc: 0.9838\n",
            "Epoch 00019: val_loss improved from 0.88231 to 0.86279, saving model to model3.h5\n",
            "301/301 [==============================] - 70s 233ms/step - loss: 0.1489 - acc: 0.9838 - val_loss: 0.8628 - val_acc: 0.8619 - lr: 1.0000e-05\n",
            "Epoch 20/20\n",
            "301/301 [==============================] - ETA: 0s - loss: 0.1209 - acc: 0.9892\n",
            "Epoch 00020: val_loss improved from 0.86279 to 0.85050, saving model to model3.h5\n",
            "301/301 [==============================] - 71s 236ms/step - loss: 0.1209 - acc: 0.9892 - val_loss: 0.8505 - val_acc: 0.8636 - lr: 1.0000e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1bfe70ecc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IK0dJ4Cu9q9T",
        "colab_type": "code",
        "outputId": "6017ad06-898c-4b73-d2e7-20bb1b600f53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\"\"\"Testing of the data and calculating the accuracy for testing data\"\"\"\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix \n",
        "from sklearn.metrics import accuracy_score \n",
        "from sklearn.metrics import classification_report \n",
        "\n",
        "\n",
        "\"\"\"Function for reading the images\"\"\"\n",
        "def read_image(path, size):\n",
        "    image = cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "    image = cv2.resize(image, (size, size)) # Resizing the images for equality \n",
        "    image = image / 255.0\n",
        "    image = image.astype(np.float32)\n",
        "    return image\n",
        "\n",
        "path = \"/content/bird_f\"\n",
        "#train_path = os.path.join(path, \"train/*\")\n",
        "test_path = os.path.join(path, \"test/*\") #path of test dataset\n",
        "labels_path2 = os.path.join(path, \"test_labels.csv\") #path of test_labels\n",
        "\n",
        "\n",
        "labels_df2 = pd.read_csv(labels_path2)\n",
        "#breed = labels_df[\"breed\"].unique()\n",
        "#print(\"Number of Breed: \", len(breed))\n",
        "\n",
        "#breed2id = {name: i for i, name in enumerate(breed)}\n",
        "#id2breed = {i: name for i, name in enumerate(breed)}\n",
        "\n",
        "\n",
        "\"\"\"Calling our model\"\"\"\n",
        "model = tf.keras.models.load_model(\"model3.h5\")\n",
        "\n",
        "#for i, path in tqdm(enumerate(valid_x[:10])):\n",
        "l1 = labels_df2[\"id\"] # image ids\n",
        "l2 = labels_df2[\"breed\"] # corresponding breed of bird\n",
        "\n",
        "zip1 = list(zip(l1, l2))\n",
        "\n",
        "random.shuffle((zip1)) # shuffling our data for better results\n",
        "\n",
        "res1 = list(zip(*zip1))\n",
        "\n",
        "l1 = list(res1[0])\n",
        "l2 = list(res1[1])\n",
        "\n",
        "predicted=[] # predicted array for breed of images\n",
        "for i in range(len(l1)):\n",
        "    image = read_image(path + \"/\" + \"test/\" + str(l1[i]) + \".png\", 224)\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "    pred = model.predict(image)[0]\n",
        "    label_idx = np.argmax(pred)\n",
        "    breed_name = id2breed[label_idx]\n",
        "    predicted.append(breed_name)\n",
        "    \n",
        "print(accuracy_score(l2,predicted)) # Calculating the accuracy for testing data\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.870945945945946\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fcdDgFAaW4w",
        "colab_type": "code",
        "outputId": "daba3d96-8bf9-4029-9e24-bad1d116b151",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\"\"\"Calculating accuracy of our model for training data\"\"\"\n",
        "#importing necessery libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix \n",
        "from sklearn.metrics import accuracy_score \n",
        "from sklearn.metrics import classification_report \n",
        "\n",
        "#Function for reainf the images\n",
        "def read_image(path, size):\n",
        "    image = cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "    image = cv2.resize(image, (size, size))\n",
        "    image = image / 255.0\n",
        "    image = image.astype(np.float32)\n",
        "    return image\n",
        "\n",
        "path = \"/content/bird_f\"\n",
        "#train_path = os.path.join(path, \"train/*\")\n",
        "#test_path = os.path.join(path, \"test/*\") \n",
        "labels_path2 = os.path.join(path, \"train_labels.csv\") #path of train labels\n",
        "\n",
        "\n",
        "labels_df2 = pd.read_csv(labels_path2)\n",
        "#breed = labels_df[\"breed\"].unique()\n",
        "#print(\"Number of Breed: \", len(breed))\n",
        "\n",
        "#breed2id = {name: i for i, name in enumerate(breed)}\n",
        "#id2breed = {i: name for i, name in enumerate(breed)}\n",
        "\n",
        "\"\"\"Calling our model\"\"\"\n",
        "model = tf.keras.models.load_model(\"model3.h5\")\n",
        "\n",
        "#for i, path in tqdm(enumerate(valid_x[:10])):\n",
        "l1 = labels_df2[\"id\"] # id of bird\n",
        "l2 = labels_df2[\"breed\"] #coresponding brred of l1 list\n",
        "\n",
        "zip1 = list(zip(l1, l2))\n",
        "\n",
        "random.shuffle((zip1)) #shuffling for unbiasing \n",
        " \n",
        "res1 = list(zip(*zip1))\n",
        "\n",
        "l1 = list(res1[0])\n",
        "l2 = list(res1[1])\n",
        "\n",
        "predicted=[] # predicated breed for training labels\n",
        "for i in range(len(l1)):\n",
        "    image = read_image(path + \"/\" + \"train/\" + str(l1[i]) + \".png\", 224)\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "    pred = model.predict(image)[0]\n",
        "    label_idx = np.argmax(pred)\n",
        "    breed_name = id2breed[label_idx]\n",
        "    predicted.append(breed_name)\n",
        "    \n",
        "print(accuracy_score(l2,predicted)) # calculating accuracy of our model for training data\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9264436678315859\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
